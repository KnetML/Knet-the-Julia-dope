{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Knet\n",
    "Knet.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Linux\n",
      "Julia: 0.6.0\n",
      "Knet: 0.8.5+\n",
      "GPU: NVS 310\n",
      "TITAN X (Pascal)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "println(\"OS: \", Sys.KERNEL)\n",
    "println(\"Julia: \", VERSION)\n",
    "println(\"Knet: \", Pkg.installed(\"Knet\"))\n",
    "println(\"GPU: \", readstring(`nvidia-smi --query-gpu=name --format=csv,noheader`))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "function initmodel(; atype=KnetArray, dtype=Float32, winit=xavier, binit=zeros)\n",
    "    w(dims...)=atype(winit(dtype,dims...))\n",
    "    b(dims...)=atype(binit(dtype,dims...))\n",
    "    return Any[\n",
    "        w(3,3,3,50), b(1,1,50,1),\n",
    "        w(3,3,50,50), b(1,1,50,1),\n",
    "        w(3,3,50,100), b(1,1,100,1),\n",
    "        w(3,3,100,100), b(1,1,100,1),\n",
    "        w(512,6400), b(512,1),\n",
    "        w(10,512), b(10,1)\n",
    "    ]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss and its gradient\n",
    "function predict(w,x)\n",
    "    convbias(x,w,b) = conv4(w,x;padding=1) .+ b\n",
    "    fc(x,w,b) = w * mat(x) .+ b;\n",
    "    x = relu.(convbias(x,w[1],w[2]))\n",
    "    x = relu.(pool(convbias(x,w[3],w[4])))\n",
    "    x = dropout(x,0.25)\n",
    "    x = relu.(convbias(x,w[5],w[6]))\n",
    "    x = relu.(pool(convbias(x,w[7],w[8])))\n",
    "    x = dropout(x,0.25)\n",
    "    x = relu.(fc(x,w[9],w[10]))\n",
    "    x = dropout(x,0.5)\n",
    "    return fc(x,w[11],w[12])\n",
    "end\n",
    "\n",
    "loss(w,x,y)=nll(predict(w,x),y) # nll: negative log likelihood\n",
    "lossgradient = grad(loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mMethodError: no method matching randn(::MersenneTwister, ::Type{Array{Float32,N} where N})\u001b[0m\nClosest candidates are:\n  randn(::AbstractRNG, ::Type{T}, \u001b[91m::Tuple{Vararg{Int64,N}} where N\u001b[39m) where T at random.jl:1292\n  randn(::AbstractRNG, ::Type{T}, \u001b[91m::Integer\u001b[39m, \u001b[91m::Integer...\u001b[39m) where T at random.jl:1294\n  randn(::AbstractRNG) at random.jl:1205\n  ...\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mMethodError: no method matching randn(::MersenneTwister, ::Type{Array{Float32,N} where N})\u001b[0m\nClosest candidates are:\n  randn(::AbstractRNG, ::Type{T}, \u001b[91m::Tuple{Vararg{Int64,N}} where N\u001b[39m) where T at random.jl:1292\n  randn(::AbstractRNG, ::Type{T}, \u001b[91m::Integer\u001b[39m, \u001b[91m::Integer...\u001b[39m) where T at random.jl:1294\n  randn(::AbstractRNG) at random.jl:1205\n  ...\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mrandn!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::MersenneTwister, ::Array{Array{Float32,N} where N,4}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./random.jl:1284\u001b[22m\u001b[22m",
      " [2] \u001b[1mrandn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::MersenneTwister, ::Type{Array{Float32,N} where N}, ::Int64, ::Int64, ::Vararg{Int64,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./random.jl:1294\u001b[22m\u001b[22m",
      " [3] \u001b[1mrandn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Type{Array{Float32,N} where N}, ::Int64, ::Int64, ::Int64, ::Vararg{Int64,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./random.jl:1296\u001b[22m\u001b[22m",
      " [4] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "xtrn = randn(Array{Float32}, 32,32,3,50000);\n",
    "ytrn = ones(Array{UInt8}, 50000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mreplacing docs for 'cifarurl :: Union{}' in module 'Main'.\u001b[39m\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mreplacing docs for 'cifardir :: Union{}' in module 'Main'.\u001b[39m\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mreplacing docs for 'cifar10 :: Tuple{}' in module 'Main'.\u001b[39m\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mreplacing docs for 'cifar100 :: Tuple{}' in module 'Main'.\u001b[39m\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mreplacing docs for 'cifarview :: Tuple{Any,Any}' in module 'Main'.\u001b[39m\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mReading cifar-10-binary.tar.gz...\n",
      "\u001b[39m"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mSystemError: opening file /home/manuel/.julia/v0.6/Knet/data/cifar/cifar-10-batches-bin/data_batch_2.bin: No such file or directory\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mSystemError: opening file /home/manuel/.julia/v0.6/Knet/data/cifar/cifar-10-batches-bin/data_batch_2.bin: No such file or directory\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1m#systemerror#44\u001b[22m\u001b[22m at \u001b[1m./error.jl:64\u001b[22m\u001b[22m [inlined]",
      " [2] \u001b[1msystemerror\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Bool\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./error.jl:64\u001b[22m\u001b[22m",
      " [3] \u001b[1mopen\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./iostream.jl:104\u001b[22m\u001b[22m",
      " [4] \u001b[1mopen\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Base.##190#191{Tuple{}}, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./iostream.jl:150\u001b[22m\u001b[22m",
      " [5] \u001b[1m_cifar_read_file\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/manuel/.julia/v0.6/Knet/data/cifar.jl:70\u001b[22m\u001b[22m",
      " [6] \u001b[1m_cifar_read_files\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Array{String,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/manuel/.julia/v0.6/Knet/data/cifar.jl:63\u001b[22m\u001b[22m",
      " [7] \u001b[1m_cifar_read_tgz\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String, ::Array{String,1}, ::Array{String,1}, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/manuel/.julia/v0.6/Knet/data/cifar.jl:54\u001b[22m\u001b[22m",
      " [8] \u001b[1m#cifar10#54\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String, ::Array{String,1}, ::Array{String,1}, ::String, ::Function\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/manuel/.julia/v0.6/Knet/data/cifar.jl:17\u001b[22m\u001b[22m",
      " [9] \u001b[1mcifar10\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/manuel/.julia/v0.6/Knet/data/cifar.jl:15\u001b[22m\u001b[22m",
      " [10] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "include(Knet.dir(\"data\",\"cifar.jl\"))\n",
    "(xtrn,ytrn,xtst,ytst,lbls)=cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for training\n",
    "model = optim = nothing; knetgc() # Clear memory from last run\n",
    "model = initmodel()\n",
    "optim = optimizers(model, Momentum;);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mcudnn.cudnnConvolutionForward error 3\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mcudnn.cudnnConvolutionForward error 3\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m/home/manuel/.julia/v0.6/Knet/src/gpu.jl:13\u001b[22m\u001b[22m [inlined]",
      " [2] \u001b[1m#conv4#194\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Ptr{Void}, ::Int64, ::Array{Any,1}, ::Function, ::Knet.KnetArray{Float32,4}, ::Knet.KnetArray{Float32,4}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/manuel/.julia/v0.6/Knet/src/conv.jl:37\u001b[22m\u001b[22m",
      " [3] \u001b[1m(::Knet.#kw##conv4)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Knet.#conv4, ::Knet.KnetArray{Float32,4}, ::Knet.KnetArray{Float32,4}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m",
      " [4] \u001b[1m(::AutoGrad.##rfun#7#10{Knet.#conv4})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::AutoGrad.Rec{Knet.KnetArray{Float32,4}}, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/manuel/.julia/v0.6/AutoGrad/src/core.jl:123\u001b[22m\u001b[22m",
      " [5] \u001b[1m(::AutoGrad.#kw##rfun#9)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::AutoGrad.#rfun#9, ::AutoGrad.Rec{Knet.KnetArray{Float32,4}}, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m",
      " [6] \u001b[1m(::Knet.##conv4#203#212{AutoGrad.#rfun#9})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::AutoGrad.Rec{Knet.KnetArray{Float32,4}}, ::Knet.KnetArray{Float32,4}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m",
      " [7] \u001b[1m(::Knet.#kw##conv4)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Knet.#conv4, ::AutoGrad.Rec{Knet.KnetArray{Float32,4}}, ::Knet.KnetArray{Float32,4}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m",
      " [8] \u001b[1mpredict\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::AutoGrad.Rec{Array{Any,1}}, ::Knet.KnetArray{Float32,4}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[6]:5\u001b[22m\u001b[22m",
      " [9] \u001b[1mloss\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::AutoGrad.Rec{Array{Any,1}}, ::Knet.KnetArray{Float32,4}, ::Array{UInt8,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[6]:16\u001b[22m\u001b[22m",
      " [10] \u001b[1mforward_pass\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Function, ::Tuple{Array{Any,1},Knet.KnetArray{Float32,4},Array{UInt8,1}}, ::Array{Any,1}, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/manuel/.julia/v0.6/AutoGrad/src/core.jl:88\u001b[22m\u001b[22m",
      " [11] \u001b[1m(::AutoGrad.##gradfun#1#3{#loss,Int64})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::Array{Any,1}, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/manuel/.julia/v0.6/AutoGrad/src/core.jl:39\u001b[22m\u001b[22m",
      " [12] \u001b[1m(::AutoGrad.#gradfun#2)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/manuel/.julia/v0.6/AutoGrad/src/core.jl:39\u001b[22m\u001b[22m",
      " [13] \u001b[1mmacro expansion\u001b[22m\u001b[22m at \u001b[1m./In[22]:3\u001b[22m\u001b[22m [inlined]",
      " [14] \u001b[1manonymous\u001b[22m\u001b[22m at \u001b[1m./<missing>:?\u001b[22m\u001b[22m",
      " [15] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "# cold start\n",
    "for (x,y) in minibatch(xtrn,ytrn,100;shuffle=true,xtype=KnetArray)\n",
    "    grads = lossgradient(model, x, y)\n",
    "    update!(model, grads, optim)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
